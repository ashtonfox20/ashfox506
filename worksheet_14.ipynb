{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 14\n",
    "\n",
    "Name:  Ashton Fox  \n",
    "UID: U95686268\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Naive Bayes\n",
    "- Model Evaluation\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "| Attribute A | Attribute B | Attribute C | Class |\n",
    "|-------------|-------------|-------------|-------|\n",
    "| Yes         | Single      | High        | No    |\n",
    "| No          | Married     | Mid         | No    |\n",
    "| No          | Single      | Low         | No    |\n",
    "| Yes         | Married     | High        | No    |\n",
    "| No          | Divorced    | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| Yes         | Divorced    | High        | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "| No          | Married     | Low         | No    |\n",
    "| No          | Single      | Mid         | Yes   |\n",
    "\n",
    "a) Compute the following probabilities:\n",
    "\n",
    "- P(Attribute A = Yes | Class = No)\n",
    "- P(Attribute B = Divorced | Class = Yes)\n",
    "- P(Attribute C = High | Class = No)\n",
    "- P(Attribute C = Mid | Class = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(A = Yes | Class = No) = 3/7\n",
    "\n",
    "P(B = Divorced | Class = Yes) = 1/3\n",
    "\n",
    "P(C = High | Class = No) = 3/7 \n",
    "\n",
    "P(C = Mid | Class = Yes) = 3/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Classify the following unseen records:\n",
    "\n",
    "- (Yes, Married, Mid)\n",
    "- (No, Divorced, High)\n",
    "- (No, Single, High)\n",
    "- (No, Divorced, Low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(yes | C = yes)P(Married | C = yes)P(Mid | C = yes)P(yes) = 0 \n",
    "\n",
    "vs\n",
    "\n",
    "P(yes | C = no)P(Married | C = no)P(Mid | C = no)P(no) = 3/7 * 4/7 * 1/7 * 7/10\n",
    "\n",
    "P(no | C = yes)P(Divorced | C = yes)P(Mid | C = yes)P(yes) = 1 * 1/3 * 1 * 3/10\n",
    "\n",
    "vs\n",
    "\n",
    "P(no | C = no)P(Divorced | C = no)P(Mid | C = no)P(no) = 4/7 * 1/7 * 1/7 * 7/10\n",
    "\n",
    "P(no | C = yes)P(Single | C = yes)P(High | C = yes)P(yes) = 0\n",
    "\n",
    "vs\n",
    "\n",
    "P(no | C = no)P(Single | C = no)P(High | C = no)P(no) = 4/7 * 2/7 * 3/7 * 7/10\n",
    "\n",
    "P(no | C = yes)P(Divorced | C = yes)P(Low | C = yes)P(yes) = 0\n",
    "\n",
    "vs\n",
    "\n",
    "P(no | C = no)P(Divorced | C = no)P(Low | C = no)P(no) = 4/7 * 1/7 * 3/7 * 7/10\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "a) Write a function to generate the confusion matrix for a list of actual classes and a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Predicted |\n",
      "|  Y     N  |\n",
      "|-----------|--------\n",
      "|  2  |  1  | Y\n",
      "|-----------|   Acutal\n",
      "|  3  |  4  | N\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_class = [\"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\"]\n",
    "predicted_class = [\"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\"]\n",
    "\n",
    "def confusion_matrix(actual, predicted, output=False):\n",
    "    # Count four possible probabilities\n",
    "    # Variables are formatted as {predicted}_{actual}\n",
    "    yes_yes, yes_no, no_no, no_yes = 0,0,0,0\n",
    "    for i in range(len(actual)):\n",
    "        if predicted[i] == \"Yes\":\n",
    "            if actual[i] == predicted[i]:\n",
    "                yes_yes += 1\n",
    "            else:\n",
    "                yes_no += 1\n",
    "        else:\n",
    "            if actual[i] == predicted[i]:\n",
    "                no_no += 1\n",
    "            else:\n",
    "                no_yes += 1\n",
    "                \n",
    "    # Format printing\n",
    "    if output:\n",
    "        print(\"| Predicted |\")\n",
    "        print(\"|  Y     N  |\")\n",
    "        print(\"|-----------|--------\")\n",
    "        print(f\"|  {yes_yes}  |  {no_yes}  | Y\")\n",
    "        print(\"|-----------|   Acutal\")\n",
    "        print(f\"|  {yes_no}  |  {no_no}  | N\")\n",
    "    return [yes_yes, no_yes, yes_no, no_no]\n",
    "\n",
    "confusion_matrix(actual_class, predicted_class, output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Assume you have the following Cost Matrix:\n",
    "\n",
    "|            | predicted = Y | predicted = N |\n",
    "|------------|---------------|---------------|\n",
    "| actual = Y |       -1      |       5       |\n",
    "| actual = N |        10     |       0       |\n",
    "\n",
    "What is the cost of the above classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to calculate cost, we find the sum of multiplying the similar entries in the matrix: (-1)(2) + (5)(1) + (10)(3) + (0)(4) = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that takes in the actual values, the predictions, and a cost matrix and outputs a cost. Test it on the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost(actual, predicted, cost_matrix):\n",
    "    cost = 0\n",
    "    con_matrix = confusion_matrix(actual, predicted)\n",
    "    for i in range(4):\n",
    "        cost += con_matrix[i] * cost_matrix[i]\n",
    "\n",
    "    return cost\n",
    "\n",
    "# Create cost matrix based on cell above\n",
    "cost_matrix = [-1, 5, 10, 0]\n",
    "\n",
    "cost(actual_class, predicted_class, cost_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Implement functions for the following:\n",
    "\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f-measure\n",
    "\n",
    "and apply them to the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of above example: 0.6\n",
      "Precision of above example: 0.4\n",
      "Recall of above example: 0.6666666666666666\n",
      "F-measure of above example: 0.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy(con_matrix):\n",
    "    correct = con_matrix[0] + con_matrix[3]\n",
    "    total = correct + con_matrix[1] + con_matrix[2]\n",
    "    return correct / total\n",
    "\n",
    "def precision(con_matrix):\n",
    "    a = con_matrix[0]\n",
    "    c = con_matrix[2]\n",
    "    return a / (a + c)\n",
    "\n",
    "def recall(con_matrix):\n",
    "    a = con_matrix[0]\n",
    "    b = con_matrix[1]\n",
    "    return a / (a + b)\n",
    "\n",
    "def f_measure(con_matrix):\n",
    "    p = precision(con_matrix)\n",
    "    r = recall(con_matrix)\n",
    "    return 2*r*p/(r + p)\n",
    "\n",
    "con_matrix = confusion_matrix(actual_class, predicted_class)\n",
    "print(f\"Accuracy of above example: {accuracy(con_matrix)}\")\n",
    "print(f\"Precision of above example: {precision(con_matrix)}\")\n",
    "print(f\"Recall of above example: {recall(con_matrix)}\")\n",
    "print(f\"F-measure of above example: {f_measure(con_matrix)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful code for the midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/Users/killua/scikit_learn_data/lfw_home/lfw_funneled/Ariel_Sharon/Ariel_Sharon_0070.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/Users/killua/Desktop/CS506/Worksheets/worksheet_14.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/killua/Desktop/CS506/Worksheets/worksheet_14.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m sns\u001b[39m.\u001b[39mset()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/killua/Desktop/CS506/Worksheets/worksheet_14.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Get face data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/killua/Desktop/CS506/Worksheets/worksheet_14.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m faces \u001b[39m=\u001b[39m fetch_lfw_people(min_faces_per_person\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/killua/Desktop/CS506/Worksheets/worksheet_14.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# plot face data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/killua/Desktop/CS506/Worksheets/worksheet_14.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/datasets/_lfw.py:353\u001b[0m, in \u001b[0;36mfetch_lfw_people\u001b[0;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing, return_X_y)\u001b[0m\n\u001b[1;32m    350\u001b[0m load_func \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mcache(_fetch_lfw_people)\n\u001b[1;32m    352\u001b[0m \u001b[39m# load and memoize the pairs as np arrays\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m faces, target, target_names \u001b[39m=\u001b[39m load_func(\n\u001b[1;32m    354\u001b[0m     data_folder_path,\n\u001b[1;32m    355\u001b[0m     resize\u001b[39m=\u001b[39;49mresize,\n\u001b[1;32m    356\u001b[0m     min_faces_per_person\u001b[39m=\u001b[39;49mmin_faces_per_person,\n\u001b[1;32m    357\u001b[0m     color\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    358\u001b[0m     slice_\u001b[39m=\u001b[39;49mslice_,\n\u001b[1;32m    359\u001b[0m )\n\u001b[1;32m    361\u001b[0m X \u001b[39m=\u001b[39m faces\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(faces), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    363\u001b[0m fdescr \u001b[39m=\u001b[39m load_descr(\u001b[39m\"\u001b[39m\u001b[39mlfw.rst\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/memory.py:655\u001b[0m, in \u001b[0;36mMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 655\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached_call(args, kwargs)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/memory.py:598\u001b[0m, in \u001b[0;36mMemorizedFunc._cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    595\u001b[0m     must_call \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mif\u001b[39;00m must_call:\n\u001b[0;32m--> 598\u001b[0m     out, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    599\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmmap_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m         \u001b[39m# Memmap the output at the first call to be consistent with\u001b[39;00m\n\u001b[1;32m    601\u001b[0m         \u001b[39m# later calls\u001b[39;00m\n\u001b[1;32m    602\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/memory.py:856\u001b[0m, in \u001b[0;36mMemorizedFunc.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    855\u001b[0m     \u001b[39mprint\u001b[39m(format_call(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc, args, kwargs))\n\u001b[0;32m--> 856\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    857\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore_backend\u001b[39m.\u001b[39mdump_item(\n\u001b[1;32m    858\u001b[0m     [func_id, args_id], output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose)\n\u001b[1;32m    860\u001b[0m duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/datasets/_lfw.py:222\u001b[0m, in \u001b[0;36m_fetch_lfw_people\u001b[0;34m(data_folder_path, slice_, color, resize, min_faces_per_person)\u001b[0m\n\u001b[1;32m    219\u001b[0m target_names \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(person_names)\n\u001b[1;32m    220\u001b[0m target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(target_names, person_names)\n\u001b[0;32m--> 222\u001b[0m faces \u001b[39m=\u001b[39m _load_imgs(file_paths, slice_, color, resize)\n\u001b[1;32m    224\u001b[0m \u001b[39m# shuffle the faces with a deterministic RNG scheme to avoid having\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m# all faces of the same person in a row, as it would break some\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m# cross validation and learning algorithms such as SGD and online\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m# k-means that make an IID assumption\u001b[39;00m\n\u001b[1;32m    229\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(n_faces)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/datasets/_lfw.py:162\u001b[0m, in \u001b[0;36m_load_imgs\u001b[0;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[1;32m    158\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mLoading face #\u001b[39m\u001b[39m%05d\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m%05d\u001b[39;00m\u001b[39m\"\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, n_faces)\n\u001b[1;32m    160\u001b[0m \u001b[39m# Checks if jpeg reading worked. Refer to issue #3594 for more\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m# details.\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m pil_img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(file_path)\n\u001b[1;32m    163\u001b[0m pil_img \u001b[39m=\u001b[39m pil_img\u001b[39m.\u001b[39mcrop(\n\u001b[1;32m    164\u001b[0m     (w_slice\u001b[39m.\u001b[39mstart, h_slice\u001b[39m.\u001b[39mstart, w_slice\u001b[39m.\u001b[39mstop, h_slice\u001b[39m.\u001b[39mstop)\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m resize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/PIL/Image.py:3280\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3278\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message)\n\u001b[1;32m   3279\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcannot identify image file \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (filename \u001b[39mif\u001b[39;00m filename \u001b[39melse\u001b[39;00m fp)\n\u001b[0;32m-> 3280\u001b[0m \u001b[39mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/Users/killua/scikit_learn_data/lfw_home/lfw_funneled/Ariel_Sharon/Ariel_Sharon_0070.jpg'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Get face data\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "\n",
    "# plot face data\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])\n",
    "plt.show()\n",
    "\n",
    "# split train test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=150, whiten=True)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "svcpca = make_pipeline(pca, svc)\n",
    "\n",
    "# Tune model to find best values of C and gamma using cross validation\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "kfold = 10\n",
    "grid = GridSearchCV(svcpca, param_grid, cv=kfold)\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# use the best params explicitly here\n",
    "pca = PCA(n_components=150, whiten=True)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced', C=10, gamma=0.005)\n",
    "svcpca = make_pipeline(pca, svc)\n",
    "\n",
    "model = BaggingClassifier(svcpca, n_estimators=100).fit(Xtrain, ytrain)\n",
    "yfit = model.predict(Xtest)\n",
    "\n",
    "fig, ax = plt.subplots(6, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)\n",
    "plt.show()\n",
    "\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(ytest, yfit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
